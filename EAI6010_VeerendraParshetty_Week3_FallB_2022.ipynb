{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQtKwPaGbeLrnrJ2SSh6DZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whoviren/whoviren/blob/main/EAI6010_VeerendraParshetty_Week3_FallB_2022.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TITLE\n",
        "**EAI6010 - Module 3: NLP AI Applications** \n",
        "\n",
        "**Submitted to - Professor Vladimir Shapiro**"
      ],
      "metadata": {
        "id": "OF1Xh_Bnp2dd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# INTRODUCTION\n",
        "Natural Language Processing (NLP) is a part of AI (artificial intelligence) that deals with understanding and processing of human language. NLP use casea are speech recognition, languague processing and sentimental analysis. In this project we will be using to Gutenberg corpus to analyze text."
      ],
      "metadata": {
        "id": "dPtYN3xwqpo9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANALYSIS"
      ],
      "metadata": {
        "id": "4BxQ0Kisqib0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1:** \n",
        "**A. Download and install the Gutenberg corpus tool to your Jupyter Notebook. Project**\n",
        "\n",
        "Gutenberg contains some 25,000 free electronic books hosted at \n",
        "http://www.gutenberg.org/. We can install the NLTK package, then use the \n",
        "Gutenberg corpus in it. "
      ],
      "metadata": {
        "id": "ctI14AZyqtan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLEJk4S7rEr9",
        "outputId": "9f7c3d04-9633-43a9-a5c3-311584ff7bc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**B. Download the Gutenberg corpus tool in the NLTK package.**"
      ],
      "metadata": {
        "id": "CToeSO4lrSFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('gutenberg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nK2kmLFlraDY",
        "outputId": "5df14625-ea7d-4d26-bebd-4ddd36c19e3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**C. Use the texts in the corpus.**\n",
        "\n",
        "Gutenberg electronic text archive contains some 25,000 free electronic books. We can use the file identifier command to check the files in this corpus"
      ],
      "metadata": {
        "id": "cIE3B1nKy4tF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.corpus.gutenberg.fileids()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQ9v1GAky7vY",
        "outputId": "309f8e97-7cd2-4692-f6fa-92d670eff871"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['austen-emma.txt',\n",
              " 'austen-persuasion.txt',\n",
              " 'austen-sense.txt',\n",
              " 'bible-kjv.txt',\n",
              " 'blake-poems.txt',\n",
              " 'bryant-stories.txt',\n",
              " 'burgess-busterbrown.txt',\n",
              " 'carroll-alice.txt',\n",
              " 'chesterton-ball.txt',\n",
              " 'chesterton-brown.txt',\n",
              " 'chesterton-thursday.txt',\n",
              " 'edgeworth-parents.txt',\n",
              " 'melville-moby_dick.txt',\n",
              " 'milton-paradise.txt',\n",
              " 'shakespeare-caesar.txt',\n",
              " 'shakespeare-hamlet.txt',\n",
              " 'shakespeare-macbeth.txt',\n",
              " 'whitman-leaves.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**D.  Create a table displaying relative frequencies with which “modals” (can, could, may, might, will, would, and should) are used in all texts provided in the corpus.**"
      ],
      "metadata": {
        "id": "99ySujD1wSck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import gutenberg\n",
        "modals = ['can', 'could', 'may', 'might', 'will', 'would','should']\n",
        "cfdist = nltk.ConditionalFreqDist((word, file) \n",
        "                                  for file in gutenberg.fileids() \n",
        "                                  for word in gutenberg.words(file) \n",
        "                                  if word in modals)"
      ],
      "metadata": {
        "id": "qRHEZ614y98B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "cfdist = pd.DataFrame(cfdist)\n",
        "cfdist"
      ],
      "metadata": {
        "id": "Liw2A4n6BDZJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 956
        },
        "outputId": "9e9b03da-198f-4103-d4c8-906bac82f84a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         would  could  might  will   may  should  can\n",
              "austen-emma.txt            815    825    322   559   213     366  270\n",
              "austen-persuasion.txt      351    444    166   162    87     185  100\n",
              "austen-sense.txt           507    568    215   354   169     228  206\n",
              "bible-kjv.txt              443    165    475  3807  1024     768  213\n",
              "blake-poems.txt              3      3      2     3     5       6   20\n",
              "bryant-stories.txt         110    154     23   144    18      38   75\n",
              "burgess-busterbrown.txt     46     56     17    19     3      13   23\n",
              "carroll-alice.txt           70     73     28    24    11      27   57\n",
              "chesterton-ball.txt        139    117     69   198    90      75  131\n",
              "chesterton-brown.txt       132    170     71   111    47      56  126\n",
              "chesterton-thursday.txt    116    148     71   109    56      54  117\n",
              "edgeworth-parents.txt      503    420    127   517   160     271  340\n",
              "melville-moby_dick.txt     421    215    183   379   230     181  220\n",
              "milton-paradise.txt         49     62     98   161   116      55  107\n",
              "shakespeare-caesar.txt      40     18     12   129    35      38   16\n",
              "shakespeare-hamlet.txt      60     26     28   131    56      52   33\n",
              "shakespeare-macbeth.txt     42     15      5    62    30      41   21\n",
              "whitman-leaves.txt          85     49     26   261    85      42   88"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-db57f473-2d7c-4b83-8cf6-3973da9135e0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>would</th>\n",
              "      <th>could</th>\n",
              "      <th>might</th>\n",
              "      <th>will</th>\n",
              "      <th>may</th>\n",
              "      <th>should</th>\n",
              "      <th>can</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>austen-emma.txt</th>\n",
              "      <td>815</td>\n",
              "      <td>825</td>\n",
              "      <td>322</td>\n",
              "      <td>559</td>\n",
              "      <td>213</td>\n",
              "      <td>366</td>\n",
              "      <td>270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>austen-persuasion.txt</th>\n",
              "      <td>351</td>\n",
              "      <td>444</td>\n",
              "      <td>166</td>\n",
              "      <td>162</td>\n",
              "      <td>87</td>\n",
              "      <td>185</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>austen-sense.txt</th>\n",
              "      <td>507</td>\n",
              "      <td>568</td>\n",
              "      <td>215</td>\n",
              "      <td>354</td>\n",
              "      <td>169</td>\n",
              "      <td>228</td>\n",
              "      <td>206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bible-kjv.txt</th>\n",
              "      <td>443</td>\n",
              "      <td>165</td>\n",
              "      <td>475</td>\n",
              "      <td>3807</td>\n",
              "      <td>1024</td>\n",
              "      <td>768</td>\n",
              "      <td>213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>blake-poems.txt</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bryant-stories.txt</th>\n",
              "      <td>110</td>\n",
              "      <td>154</td>\n",
              "      <td>23</td>\n",
              "      <td>144</td>\n",
              "      <td>18</td>\n",
              "      <td>38</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>burgess-busterbrown.txt</th>\n",
              "      <td>46</td>\n",
              "      <td>56</td>\n",
              "      <td>17</td>\n",
              "      <td>19</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>carroll-alice.txt</th>\n",
              "      <td>70</td>\n",
              "      <td>73</td>\n",
              "      <td>28</td>\n",
              "      <td>24</td>\n",
              "      <td>11</td>\n",
              "      <td>27</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>chesterton-ball.txt</th>\n",
              "      <td>139</td>\n",
              "      <td>117</td>\n",
              "      <td>69</td>\n",
              "      <td>198</td>\n",
              "      <td>90</td>\n",
              "      <td>75</td>\n",
              "      <td>131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>chesterton-brown.txt</th>\n",
              "      <td>132</td>\n",
              "      <td>170</td>\n",
              "      <td>71</td>\n",
              "      <td>111</td>\n",
              "      <td>47</td>\n",
              "      <td>56</td>\n",
              "      <td>126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>chesterton-thursday.txt</th>\n",
              "      <td>116</td>\n",
              "      <td>148</td>\n",
              "      <td>71</td>\n",
              "      <td>109</td>\n",
              "      <td>56</td>\n",
              "      <td>54</td>\n",
              "      <td>117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>edgeworth-parents.txt</th>\n",
              "      <td>503</td>\n",
              "      <td>420</td>\n",
              "      <td>127</td>\n",
              "      <td>517</td>\n",
              "      <td>160</td>\n",
              "      <td>271</td>\n",
              "      <td>340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>melville-moby_dick.txt</th>\n",
              "      <td>421</td>\n",
              "      <td>215</td>\n",
              "      <td>183</td>\n",
              "      <td>379</td>\n",
              "      <td>230</td>\n",
              "      <td>181</td>\n",
              "      <td>220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>milton-paradise.txt</th>\n",
              "      <td>49</td>\n",
              "      <td>62</td>\n",
              "      <td>98</td>\n",
              "      <td>161</td>\n",
              "      <td>116</td>\n",
              "      <td>55</td>\n",
              "      <td>107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>shakespeare-caesar.txt</th>\n",
              "      <td>40</td>\n",
              "      <td>18</td>\n",
              "      <td>12</td>\n",
              "      <td>129</td>\n",
              "      <td>35</td>\n",
              "      <td>38</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>shakespeare-hamlet.txt</th>\n",
              "      <td>60</td>\n",
              "      <td>26</td>\n",
              "      <td>28</td>\n",
              "      <td>131</td>\n",
              "      <td>56</td>\n",
              "      <td>52</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>shakespeare-macbeth.txt</th>\n",
              "      <td>42</td>\n",
              "      <td>15</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>30</td>\n",
              "      <td>41</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>whitman-leaves.txt</th>\n",
              "      <td>85</td>\n",
              "      <td>49</td>\n",
              "      <td>26</td>\n",
              "      <td>261</td>\n",
              "      <td>85</td>\n",
              "      <td>42</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db57f473-2d7c-4b83-8cf6-3973da9135e0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-db57f473-2d7c-4b83-8cf6-3973da9135e0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-db57f473-2d7c-4b83-8cf6-3973da9135e0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**E. For two modals with the largest span of relative frequencies (most used minus least used), select a text which uses it the most and the text that uses it the least. Compare usage in both texts by examining the relative frequencies of those modals in the two texts. Try to explain why those words are used differently in the two texts**. "
      ],
      "metadata": {
        "id": "U0pWjVWtOV-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding up all the models used in corpus \n",
        "modal_count = cfdist.sum().sort_values(ascending=False)\n",
        "modal_count"
      ],
      "metadata": {
        "id": "2vg8OsO5DBwR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbcd4fd9-a55d-453e-b1f6-66fc3efdf96e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "will      7130\n",
              "would     3932\n",
              "could     3528\n",
              "should    2496\n",
              "may       2435\n",
              "can       2163\n",
              "might     1938\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now know that the most used model is the text bible and least used text is in the text blake. We should now find the "
      ],
      "metadata": {
        "id": "kR42HQNSUb2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Displying the max of modal 'will' in the corpus \n",
        "most_frequent_modal = modal_count.index[0]\n",
        "print(\"Most Frequent Modal : \"+ str(most_frequent_modal))\n",
        "print(\"\\n\")\n",
        "print(\"Text with maximum count of '\" + str(most_frequent_modal) + \"': \" + cfdist.loc[cfdist[most_frequent_modal]==max(cfdist[most_frequent_modal]),most_frequent_modal].index[0])\n",
        "print(\"\\n\")\n",
        "print(\"Text with minimum count of '\" + str(most_frequent_modal) + \"': \" + cfdist.loc[cfdist[most_frequent_modal]==min(cfdist[most_frequent_modal]),most_frequent_modal].index[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UT8nC2mdUQA9",
        "outputId": "425408bc-f73a-45b6-9941-ec93bb0d59bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Frequent Modal : will\n",
            "\n",
            "\n",
            "Text with maximum count of 'will': bible-kjv.txt\n",
            "\n",
            "\n",
            "Text with minimum count of 'will': blake-poems.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "least_frequent_modal = modal_count.index[-1]\n",
        "print(\"Least Frequent Modal : \"+ str(least_frequent_modal))\n",
        "print(\"\\n\")\n",
        "print(\"Text with maximum count of '\" + str(least_frequent_modal) + \"': \" + cfdist.loc[cfdist[least_frequent_modal]==max(cfdist[least_frequent_modal]),least_frequent_modal].index[0])\n",
        "print(\"\\n\")\n",
        "print(\"Text with minimum count of '\" + str(least_frequent_modal) + \"': \" + cfdist.loc[cfdist[least_frequent_modal]==min(cfdist[least_frequent_modal]),least_frequent_modal].index[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFxNK9PzVIVp",
        "outputId": "4779dba6-866b-4b4b-a361-7e1b98220aac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Least Frequent Modal : might\n",
            "\n",
            "\n",
            "Text with maximum count of 'might': bible-kjv.txt\n",
            "\n",
            "\n",
            "Text with minimum count of 'might': blake-poems.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_bible =  nltk.Text(nltk.corpus.gutenberg.words('bible-kjv.txt'))\n",
        "text_blake =  nltk.Text(nltk.corpus.gutenberg.words('blake-poems.txt'))"
      ],
      "metadata": {
        "id": "7XHl3_FhVgKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the concordance function shows us every occurrence of a given word\n",
        "\n",
        "print(text_bible.concordance(most_frequent_modal))\n",
        "print(\"\\n\")\n",
        "print(text_blake.concordance(most_frequent_modal))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWWXru8lVkQV",
        "outputId": "7217dc22-c74c-40b8-d315-59377571d55a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Displaying 25 of 3836 matches:\n",
            "ood that the man should be alone ; I will make him an help meet for him . 2 : \n",
            " the days of thy life : 3 : 15 And I will put enmity between thee and the woma\n",
            " . 3 : 16 Unto the woman he said , I will greatly multiply thy sorrow and thy \n",
            " heart . 6 : 7 And the LORD said , I will destroy man whom I have created from\n",
            "ence through them ; and , behold , I will destroy them with the earth . 6 : 14\n",
            "rth shall die . 6 : 18 But with thee will I establish my covenant ; and thou s\n",
            "h . 7 : 4 For yet seven days , and I will cause it to rain upon the earth fort\n",
            "ry living substance that I have made will I destroy from off the face of the e\n",
            "; and the LORD said in his heart , I will not again curse the ground any more \n",
            "art is evil from his youth ; neither will I again smite any more every thing l\n",
            " And surely your blood of your lives will I require ; at the hand of every bea\n",
            "require ; at the hand of every beast will I require it , and at the hand of ma\n",
            "at the hand of every man ' s brother will I require the life of man . 9 : 6 Wh\n",
            "ry beast of the earth . 9 : 11 And I will establish my covenant with you , nei\n",
            " be seen in the cloud : 9 : 15 And I will remember my covenant , which is betw\n",
            "he bow shall be in the cloud ; and I will look upon it , that I may remember t\n",
            "s they begin to do : and now nothing will be restrained from them , which they\n",
            "ather ' s house , unto a land that I will shew thee : 12 : 2 And I will make o\n",
            "that I will shew thee : 12 : 2 And I will make of thee a great nation , and I \n",
            " make of thee a great nation , and I will bless thee , and make thy name great\n",
            "u shalt be a blessing : 12 : 3 And I will bless them that bless thee , and cur\n",
            "nto Abram , and said , Unto thy seed will I give this land : and there builded\n",
            "ll say , This is his wife : and they will kill me , but they will save thee al\n",
            "e : and they will kill me , but they will save thee alive . 12 : 13 Say , I pr\n",
            "hou wilt take the left hand , then I will go to the right ; or if thou depart \n",
            "None\n",
            "\n",
            "\n",
            "Displaying 3 of 3 matches:\n",
            "arn ' d the heat to bear , The cloud will vanish , we shall hear His voice , S\n",
            "lver hair , And be like him , and he will then love me . THE BLOSSOM Merry , m\n",
            "alone nor or itself : fear not and I will call , The weak worm from its lowly \n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_bible.concordance(least_frequent_modal))\n",
        "print(\"\\n\")\n",
        "print(text_blake.concordance(least_frequent_modal))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9uGkYM7VyDa",
        "outputId": "242dd5f9-3ca9-4c4f-c790-978bc40049d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Displaying 25 of 475 matches:\n",
            "aidst thou , She is my sister ? so I might have taken her to me to wife : now t\n",
            "as not able to bear them , that they might dwell together : for their substance\n",
            "raham said unto God , O that Ishmael might live before thee ! 17 : 19 And God s\n",
            "ast done unto us ? one of the people might lightly have lien with thy wife , an\n",
            "And Laban said , Behold , I would it might be according to thy word . 30 : 35 A\n",
            "he cattle in the gutters , that they might conceive among the rods . 30 : 42 Bu\n",
            " me ; and didst not tell me , that I might have sent thee away with mirth , and\n",
            "heir riches were more than that they might dwell together ; and the land wherei\n",
            ", and lay no hand upon him ; that he might rid him out of their hands , to deli\n",
            "y themselves : because the Egyptians might not eat bread with the Hebrews ; for\n",
            " Reuben , thou art my firstborn , my might , and the beginning of my strength ,\n",
            "d the heart of his servants , that I might shew these my signs before him : 10 \n",
            "e urgent upon the people , that they might send them out of the land in haste ;\n",
            "o couple the tent together , that it might be one . 36 : 19 And he made a cover\n",
            " ephod with a lace of blue , that it might be above the curious girdle of the e\n",
            "the ephod , and that the breastplate might not be loosed from the ephod ; as th\n",
            " in ward , that the mind of the LORD might be shewed them . 24 : 13 And the LOR\n",
            "in the sight of the heathen , that I might be their God : I am the LORD . 26 : \n",
            "amilies of the Kohathites , all that might do service in the tabernacle of the \n",
            "of the sons of Gershon , of all that might do service in the tabernacle of the \n",
            "hou broughtest up this people in thy might from among them ;) 14 : 14 And they \n",
            "high places of Baal , that thence he might see the utmost part of the people . \n",
            "d made his heart obstinate , that he might deliver him into thy hand , as appea\n",
            " to thy works , and according to thy might ? 3 : 25 I pray thee , let me go ove\n",
            "you statutes and judgments , that ye might do them in the land whither ye go ov\n",
            "None\n",
            "\n",
            "\n",
            "Displaying 2 of 2 matches:\n",
            "nd weeping in the evening dew ; That might control The starry pole , And fallen\n",
            "he Church to stray . Then the Parson might preach , and drink , and sing , And \n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2:** \n",
        "**A. In the Inaugural corpus, see below:** "
      ],
      "metadata": {
        "id": "9VKhWpr-DDbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we are loading the inagural corpus \n",
        "nltk.download('inaugural')\n",
        "from nltk.corpus import inaugural"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjIA9mbmDE1W",
        "outputId": "0a18ab13-51ca-4b3f-fda8-e132a333c777"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]   Package inaugural is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**B.Chose Kennedy’s speech, using e.g., this code:**"
      ],
      "metadata": {
        "id": "Nuhn4AgSGwYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choosing the '1961-Kennedy text' \n",
        "nltk.corpus.inaugural.words('1961-Kennedy.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQXEpTuKGyr2",
        "outputId": "40285d75-07f7-4a53-fc93-f072aef87811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Vice', 'President', 'Johnson', ',', 'Mr', '.', ...]"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**C. Identify the 10 most frequently used long words (words longer than 7 characters).**"
      ],
      "metadata": {
        "id": "Ie3l6q3uMhYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First we load all the words \n",
        "\n",
        "ken_words = nltk.corpus.inaugural.words('1961-Kennedy.txt')"
      ],
      "metadata": {
        "id": "ihMYNnmHPVdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking lenght of words\n",
        "len(ken_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuUOCa57XK_I",
        "outputId": "892c3736-89c5-4a36-c6de-b6e7b7254070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1546"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtering the words lonnger than 7 charecters in Kennedy text and turning the words to lower case \n",
        "\n",
        "filt_char_7 = ([w.lower() for w in ken_words if len(w) > 7])"
      ],
      "metadata": {
        "id": "3oWL8h9EVNfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe from the above table that the word 'citizens' had the highest occurences."
      ],
      "metadata": {
        "id": "xulKX2uxY_mh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Frequency distribution\n",
        "\n",
        "from nltk import FreqDist\n",
        "f_dist = FreqDist(filt_char_7)\n",
        "freq = f_dist.most_common(10)"
      ],
      "metadata": {
        "id": "hrKxtGUgVx2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKUiGU9yZFZe",
        "outputId": "09ac08cc-2d2d-42b0-cc6f-3efb807f1eac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('citizens', 5),\n",
              " ('president', 4),\n",
              " ('americans', 4),\n",
              " ('generation', 3),\n",
              " ('forebears', 2),\n",
              " ('revolution', 2),\n",
              " ('committed', 2),\n",
              " ('powerful', 2),\n",
              " ('supporting', 2),\n",
              " ('themselves', 2)]"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating an empty arrays\n",
        "ken_1 = []\n",
        "ken_2 = []\n",
        "\n",
        "# Seperating the words\n",
        "for i in range(10):\n",
        "    ken_1.append(freq[i][0])\n",
        "\n",
        "for i in range(10):\n",
        "    ken_2.append(freq[i][1])\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Creating dataframe\n",
        "df_freq_kennedy = pd.DataFrame({'Top 10':ken_1, 'Frequency':ken_2})"
      ],
      "metadata": {
        "id": "hX9LKI0uWmJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing top 10 words in Kennedy text with most occurences \n",
        "df_freq_kennedy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "h144OIhKXyoh",
        "outputId": "969b91bb-2dfd-4d7e-eb10-27b347c48f13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Top 10  Frequency\n",
              "0    citizens          5\n",
              "1   president          4\n",
              "2   americans          4\n",
              "3  generation          3\n",
              "4   forebears          2\n",
              "5  revolution          2\n",
              "6   committed          2\n",
              "7    powerful          2\n",
              "8  supporting          2\n",
              "9  themselves          2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-623c8ac0-8f11-4a9e-8306-714cef0a6f00\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Top 10</th>\n",
              "      <th>Frequency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>citizens</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>president</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>americans</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>generation</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>forebears</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>revolution</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>committed</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>powerful</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>supporting</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>themselves</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-623c8ac0-8f11-4a9e-8306-714cef0a6f00')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-623c8ac0-8f11-4a9e-8306-714cef0a6f00 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-623c8ac0-8f11-4a9e-8306-714cef0a6f00');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a list \n",
        "top_10_list = df_freq_kennedy['Top 10'].to_list()"
      ],
      "metadata": {
        "id": "nPnSkB6GZ0Mi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_10_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPtsDTp6aSFA",
        "outputId": "e1418874-e18c-4f37-c6d1-91b826d25063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['citizens',\n",
              " 'president',\n",
              " 'americans',\n",
              " 'generation',\n",
              " 'forebears',\n",
              " 'revolution',\n",
              " 'committed',\n",
              " 'powerful',\n",
              " 'supporting',\n",
              " 'themselves']"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**D.  Which one of those 10 words has the largest number of synonyms? Use WordNet as a helper.**"
      ],
      "metadata": {
        "id": "bWvDOd0La8lv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZYE-9mya_ng",
        "outputId": "4c32ca91-8314-46b9-d372-f18abd14ca77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# blank dictionary\n",
        "synonyms = []\n",
        "\n",
        "# traverse through top 10 words list created earlier \n",
        "for word in top_10_list:\n",
        "  print(word)\n",
        "  for j in wn.synsets(word):\n",
        "    for s in j.lemmas():\n",
        "      synonyms.append(s.name())\n",
        "  print(set(synonyms))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Jx4Ut5EZokZ",
        "outputId": "a83a3671-aad6-4b5f-a905-dd2e7527b13a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "citizens\n",
            "{'citizen'}\n",
            "president\n",
            "{'United_States_President', 'president', 'President_of_the_United_States', 'President', 'chairman', 'chair', 'citizen', 'Chief_Executive', 'chairwoman', 'chairperson', 'prexy'}\n",
            "americans\n",
            "{'United_States_President', 'president', 'President_of_the_United_States', 'President', 'chairman', 'chair', 'American', 'American_English', 'citizen', 'Chief_Executive', 'chairwoman', 'chairperson', 'American_language', 'prexy'}\n",
            "generation\n",
            "{'President_of_the_United_States', 'Chief_Executive', 'chairperson', 'coevals', 'genesis', 'President', 'propagation', 'American_English', 'American_language', 'United_States_President', 'president', 'contemporaries', 'chair', 'citizen', 'prexy', 'chairman', 'American', 'chairwoman', 'multiplication', 'generation'}\n",
            "forebears\n",
            "{'President_of_the_United_States', 'Chief_Executive', 'chairperson', 'coevals', 'genesis', 'President', 'propagation', 'American_English', 'American_language', 'forebear', 'United_States_President', 'president', 'contemporaries', 'chair', 'citizen', 'prexy', 'chairman', 'American', 'chairwoman', 'multiplication', 'generation', 'forbear'}\n",
            "revolution\n",
            "{'President_of_the_United_States', 'rotation', 'Chief_Executive', 'chairperson', 'coevals', 'genesis', 'President', 'propagation', 'American_English', 'American_language', 'forebear', 'United_States_President', 'president', 'contemporaries', 'chair', 'revolution', 'citizen', 'gyration', 'prexy', 'chairman', 'American', 'chairwoman', 'multiplication', 'generation', 'forbear'}\n",
            "committed\n",
            "{'consecrate', 'President_of_the_United_States', 'dedicate', 'rotation', 'send', 'committed', 'Chief_Executive', 'chairperson', 'coevals', 'genesis', 'entrust', 'President', 'propagation', 'invest', 'commit', 'place', 'American_English', 'intrust', 'attached', 'give', 'American_language', 'institutionalize', 'institutionalise', 'put', 'practice', 'forebear', 'United_States_President', 'president', 'contemporaries', 'chair', 'pull', 'revolution', 'trust', 'citizen', 'gyration', 'prexy', 'confide', 'perpetrate', 'chairman', 'devote', 'American', 'chairwoman', 'charge', 'multiplication', 'generation', 'forbear'}\n",
            "powerful\n",
            "{'consecrate', 'President_of_the_United_States', 'dedicate', 'rotation', 'mighty', 'send', 'committed', 'Chief_Executive', 'chairperson', 'coevals', 'genesis', 'hefty', 'brawny', 'entrust', 'President', 'propagation', 'invest', 'commit', 'place', 'American_English', 'intrust', 'attached', 'give', 'American_language', 'institutionalize', 'institutionalise', 'put', 'practice', 'powerful', 'forebear', 'United_States_President', 'president', 'contemporaries', 'muscular', 'chair', 'pull', 'revolution', 'trust', 'citizen', 'sinewy', 'gyration', 'knock-down', 'prexy', 'mightily', 'herculean', 'confide', 'right', 'potent', 'perpetrate', 'chairman', 'devote', 'American', 'chairwoman', 'charge', 'multiplication', 'generation', 'forbear'}\n",
            "supporting\n",
            "{'underpin', 'chairperson', 'back', 'invest', 'place', 'digest', 'put', 'practice', 'institutionalize', 'president', 'contemporaries', 'put_up', 'bear', 'sustain', 'pull', 'knock-down', 'supporting', 'potent', 'devote', 'generation', 'mighty', 'send', 'tolerate', 'confirm', 'endure', 'hefty', 'brawny', 'patronage', 'give', 'institutionalise', 'powerful', 'endorse', 'plump_for', 'United_States_President', 'corroborate', 'citizen', 'sinewy', 'prexy', 'patronize', 'bear_out', 'abide', 'herculean', 'confide', 'perpetrate', 'hold_up', 'fend_for', 'committed', 'back_up', 'subscribe', 'substantiate', 'genesis', 'entrust', 'propagation', 'commit', 'attached', 'forebear', 'brook', 'stick_out', 'muscular', 'revolution', 'indorse', 'gyration', 'suffer', 'mightily', 'support', 'keep_going', 'American', 'multiplication', 'consecrate', 'President_of_the_United_States', 'dedicate', 'rotation', 'Chief_Executive', 'load-bearing', 'coevals', 'encouraging', 'affirm', 'President', 'American_English', 'intrust', 'American_language', 'hold', 'stand', 'patronise', 'defend', 'chair', 'trust', 'plunk_for', 'right', 'chairman', 'chairwoman', 'charge', 'stomach', 'forbear'}\n",
            "themselves\n",
            "{'underpin', 'chairperson', 'back', 'invest', 'place', 'digest', 'put', 'practice', 'institutionalize', 'president', 'contemporaries', 'put_up', 'bear', 'sustain', 'pull', 'knock-down', 'supporting', 'potent', 'devote', 'generation', 'mighty', 'send', 'tolerate', 'confirm', 'endure', 'hefty', 'brawny', 'patronage', 'give', 'institutionalise', 'powerful', 'endorse', 'plump_for', 'United_States_President', 'corroborate', 'citizen', 'sinewy', 'prexy', 'patronize', 'bear_out', 'abide', 'herculean', 'confide', 'perpetrate', 'hold_up', 'fend_for', 'committed', 'back_up', 'subscribe', 'substantiate', 'genesis', 'entrust', 'propagation', 'commit', 'attached', 'forebear', 'brook', 'stick_out', 'muscular', 'revolution', 'indorse', 'gyration', 'suffer', 'mightily', 'support', 'keep_going', 'American', 'multiplication', 'consecrate', 'President_of_the_United_States', 'dedicate', 'rotation', 'Chief_Executive', 'load-bearing', 'coevals', 'encouraging', 'affirm', 'President', 'American_English', 'intrust', 'American_language', 'hold', 'stand', 'patronise', 'defend', 'chair', 'trust', 'plunk_for', 'right', 'chairman', 'chairwoman', 'charge', 'stomach', 'forbear'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creaty empty arrays\n",
        "np_1 = []\n",
        "np_2 = []\n",
        "\n",
        "# Get synonyms\n",
        "for i in range(10):\n",
        "    np_1.append(np_syn[i][0])\n",
        "\n",
        "for j in range(10):\n",
        "    np_2.append(np_syn[j][1])\n",
        "\n",
        "# Create dataframe\n",
        "df_syn = pd.DataFrame({'Words':np_1, 'n':np_2})"
      ],
      "metadata": {
        "id": "RNwV-jzt3z-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Listing the word with largest number of synonyms\n",
        "df_syn.sort_values(by=\"n\", ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "6r8SuPVf4XWq",
        "outputId": "549043aa-b724-4706-c248-aac24d7d7ec9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Words   n\n",
              "8  supporting  52\n",
              "6   committed  27\n",
              "1   president  16\n",
              "7    powerful  16\n",
              "3  generation  12\n",
              "2   americans   5\n",
              "5  revolution   5\n",
              "4   forebears   2\n",
              "0    citizens   1\n",
              "9  themselves   0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-037f6221-2270-4172-b68a-60dd5c27df24\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Words</th>\n",
              "      <th>n</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>supporting</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>committed</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>president</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>powerful</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>generation</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>americans</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>revolution</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>forebears</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>citizens</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>themselves</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-037f6221-2270-4172-b68a-60dd5c27df24')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-037f6221-2270-4172-b68a-60dd5c27df24 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-037f6221-2270-4172-b68a-60dd5c27df24');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**E. List all synonyms for the 10 most frequently used words. Which one of those 10 words has the largest number of hyponyms?** "
      ],
      "metadata": {
        "id": "g110PBUhgcbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create array\n",
        "np_hyp = []\n",
        "\n",
        "# Loop through most frequent distribution \n",
        "for i in f_dist.most_common(10):\n",
        "    # Print word\n",
        "    print ('Word: '), i[0]\n",
        "    count=0\n",
        "    \n",
        "    # Print Hyponyms\n",
        "    print ('Hyponyms: ')\n",
        "    for j in wn.synsets(i[0]):\n",
        "        print (j)\n",
        "        print (j.hyponyms())\n",
        "        count+= len(j.hyponyms())\n",
        "    np_hyp.append([i[0], count])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rq0myZ6pwtPc",
        "outputId": "930544ed-8b50-4152-9d62-cc21c98a6558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: \n",
            "Hyponyms: \n",
            "Synset('citizen.n.01')\n",
            "[Synset('active_citizen.n.01'), Synset('civilian.n.01'), Synset('freeman.n.01'), Synset('private_citizen.n.01'), Synset('repatriate.n.01'), Synset('thane.n.02'), Synset('voter.n.01')]\n",
            "Word: \n",
            "Hyponyms: \n",
            "Synset('president.n.01')\n",
            "[]\n",
            "Synset('president_of_the_united_states.n.01')\n",
            "[]\n",
            "Synset('president.n.03')\n",
            "[Synset('ex-president.n.01')]\n",
            "Synset('president.n.04')\n",
            "[Synset('kalon_tripa.n.01'), Synset('vice_chairman.n.01')]\n",
            "Synset('president.n.05')\n",
            "[]\n",
            "Synset('president_of_the_united_states.n.02')\n",
            "[]\n",
            "Word: \n",
            "Hyponyms: \n",
            "Synset('american.n.01')\n",
            "[Synset('african-american.n.01'), Synset('alabaman.n.01'), Synset('alaskan.n.01'), Synset('anglo-american.n.01'), Synset('appalachian.n.01'), Synset('arizonan.n.01'), Synset('arkansan.n.01'), Synset('asian_american.n.01'), Synset('bay_stater.n.01'), Synset('bostonian.n.01'), Synset('californian.n.01'), Synset('carolinian.n.01'), Synset('coloradan.n.01'), Synset('connecticuter.n.01'), Synset('creole.n.02'), Synset('delawarean.n.01'), Synset('floridian.n.01'), Synset('franco-american.n.01'), Synset('georgian.n.01'), Synset('german_american.n.01'), Synset('hawaiian.n.02'), Synset('idahoan.n.01'), Synset('illinoisan.n.01'), Synset('indianan.n.01'), Synset('iowan.n.01'), Synset('kansan.n.01'), Synset('kentuckian.n.01'), Synset('louisianan.n.01'), Synset('mainer.n.01'), Synset('marylander.n.01'), Synset('michigander.n.01'), Synset('minnesotan.n.01'), Synset('mississippian.n.02'), Synset('missourian.n.01'), Synset('montanan.n.01'), Synset('nebraskan.n.01'), Synset('nevadan.n.01'), Synset('new_englander.n.01'), Synset('new_hampshirite.n.01'), Synset('new_jerseyan.n.01'), Synset('new_mexican.n.01'), Synset('new_yorker.n.01'), Synset('nisei.n.01'), Synset('north_carolinian.n.01'), Synset('north_dakotan.n.01'), Synset('ohioan.n.01'), Synset('oklahoman.n.01'), Synset('oregonian.n.01'), Synset('pennsylvanian.n.02'), Synset('puerto_rican.n.01'), Synset('rhode_islander.n.01'), Synset('south_carolinian.n.01'), Synset('south_dakotan.n.01'), Synset('southerner.n.01'), Synset('spanish_american.n.01'), Synset('tennessean.n.01'), Synset('texan.n.01'), Synset('tory.n.01'), Synset('utahan.n.01'), Synset('vermonter.n.01'), Synset('virginian.n.01'), Synset('washingtonian.n.01'), Synset('washingtonian.n.02'), Synset('west_virginian.n.01'), Synset('wisconsinite.n.01'), Synset('wyomingite.n.01'), Synset('yankee.n.01'), Synset('yankee.n.03')]\n",
            "Synset('american_english.n.01')\n",
            "[Synset('african_american_vernacular_english.n.01')]\n",
            "Synset('american.n.03')\n",
            "[Synset('creole.n.01'), Synset('latin_american.n.01'), Synset('mesoamerican.n.01'), Synset('north_american.n.01'), Synset('south_american.n.01'), Synset('west_indian.n.01')]\n",
            "Word: \n",
            "Hyponyms: \n",
            "Synset('coevals.n.01')\n",
            "[Synset('peer_group.n.01'), Synset('youth_culture.n.01')]\n",
            "Synset('generation.n.02')\n",
            "[Synset('baby_boom.n.01'), Synset('generation_x.n.01'), Synset('posterity.n.02')]\n",
            "Synset('generation.n.03')\n",
            "[]\n",
            "Synset('generation.n.04')\n",
            "[]\n",
            "Synset('genesis.n.01')\n",
            "[]\n",
            "Synset('generation.n.06')\n",
            "[]\n",
            "Synset('generation.n.07')\n",
            "[Synset('biogenesis.n.02')]\n",
            "Word: \n",
            "Hyponyms: \n",
            "Synset('forebear.n.01')\n",
            "[Synset('grandparent.n.01'), Synset('great_grandparent.n.01')]\n",
            "Word: \n",
            "Hyponyms: \n",
            "Synset('revolution.n.01')\n",
            "[Synset('cultural_revolution.n.01'), Synset('green_revolution.n.01')]\n",
            "Synset('revolution.n.02')\n",
            "[Synset('counterrevolution.n.01')]\n",
            "Synset('rotation.n.03')\n",
            "[Synset('axial_rotation.n.01'), Synset('dextrorotation.n.01'), Synset('levorotation.n.01'), Synset('orbital_rotation.n.01'), Synset('spin.n.01')]\n",
            "Word: \n",
            "Hyponyms: \n",
            "Synset('perpetrate.v.01')\n",
            "[Synset('make.v.24'), Synset('recommit.v.01')]\n",
            "Synset('give.v.18')\n",
            "[Synset('apply.v.10'), Synset('rededicate.v.01'), Synset('vow.v.02')]\n",
            "Synset('commit.v.03')\n",
            "[Synset('hospitalize.v.01')]\n",
            "Synset('entrust.v.01')\n",
            "[Synset('commend.v.03'), Synset('consign.v.02'), Synset('obligate.v.02'), Synset('recommit.v.02')]\n",
            "Synset('invest.v.01')\n",
            "[Synset('buy_into.v.01'), Synset('fund.v.04'), Synset('roll_over.v.03'), Synset('shelter.v.02'), Synset('speculate.v.04'), Synset('tie_up.v.02')]\n",
            "Synset('commit.v.06')\n",
            "[]\n",
            "Synset('committed.a.01')\n",
            "[]\n",
            "Synset('attached.a.03')\n",
            "[]\n",
            "Word: \n",
            "Hyponyms: \n",
            "Synset('powerful.a.01')\n",
            "[]\n",
            "Synset('knock-down.s.01')\n",
            "[]\n",
            "Synset('potent.s.01')\n",
            "[]\n",
            "Synset('brawny.s.01')\n",
            "[]\n",
            "Synset('herculean.s.01')\n",
            "[]\n",
            "Synset('mighty.r.01')\n",
            "[]\n",
            "Word: \n",
            "Hyponyms: \n",
            "Synset('support.n.08')\n",
            "[Synset('shoring.n.02'), Synset('suspension.n.06')]\n",
            "Synset('support.v.01')\n",
            "[Synset('help.v.01'), Synset('patronize.v.02'), Synset('promote.v.01'), Synset('second.v.01'), Synset('sponsor.v.02'), Synset('undergird.v.01')]\n",
            "Synset('support.v.02')\n",
            "[Synset('fund.v.06'), Synset('provide.v.06'), Synset('see_through.v.01'), Synset('sponsor.v.01'), Synset('subsidize.v.01')]\n",
            "Synset('back.v.01')\n",
            "[Synset('champion.v.01'), Synset('guarantee.v.04')]\n",
            "Synset('hold.v.10')\n",
            "[Synset('block.v.11'), Synset('brace.v.03'), Synset('bracket.v.01'), Synset('buoy.v.02'), Synset('carry.v.05'), Synset('chock.v.02'), Synset('pole.v.02'), Synset('prop_up.v.01'), Synset('scaffold.v.01'), Synset('truss.v.03'), Synset('underpin.v.01')]\n",
            "Synset('confirm.v.01')\n",
            "[Synset('back.v.09'), Synset('document.v.02'), Synset('prove.v.02'), Synset('validate.v.02'), Synset('verify.v.01'), Synset('vouch.v.04')]\n",
            "Synset('subscribe.v.03')\n",
            "[]\n",
            "Synset('corroborate.v.03')\n",
            "[]\n",
            "Synset('defend.v.01')\n",
            "[Synset('apologize.v.02'), Synset('stand_up.v.05'), Synset('uphold.v.02')]\n",
            "Synset('support.v.09')\n",
            "[]\n",
            "Synset('patronize.v.04')\n",
            "[]\n",
            "Synset('digest.v.03')\n",
            "[Synset('accept.v.07'), Synset('bear_up.v.01'), Synset('pay.v.09'), Synset('sit_out.v.02'), Synset('stand_for.v.04'), Synset('take_a_joke.v.01'), Synset('take_lying_down.v.01')]\n",
            "Synset('encouraging.s.02')\n",
            "[]\n",
            "Synset('load-bearing.s.01')\n",
            "[]\n",
            "Word: \n",
            "Hyponyms: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating empty arrays\n",
        "np_1 = []\n",
        "np_2 = []\n",
        "\n",
        "# Get synonyms\n",
        "for i in range(10):\n",
        "    np_1.append(np_hyp[i][0])\n",
        "\n",
        "for j in range(10):\n",
        "    np_2.append(np_hyp[j][1])\n",
        "\n",
        "# Create dataframe\n",
        "df_hyp = pd.DataFrame({'Top 3':np_1, 'n':np_2})"
      ],
      "metadata": {
        "id": "wnC0vD8D5Afx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**F. List all hyponyms of the 10 most frequently used words.**"
      ],
      "metadata": {
        "id": "avA0KXGy5XQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Listing the words with most appearences\n",
        "df_hyp.sort_values(by=\"n\", ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "52engAaNwtRR",
        "outputId": "8c6be839-534e-4ca6-eccb-a50b7328f1ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Top 3   n\n",
              "2   americans  75\n",
              "8  supporting  42\n",
              "6   committed  16\n",
              "5  revolution   8\n",
              "0    citizens   7\n",
              "3  generation   6\n",
              "1   president   3\n",
              "4   forebears   2\n",
              "7    powerful   0\n",
              "9  themselves   0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-02d063f5-a602-4b22-9862-34987c9ea3d6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Top 3</th>\n",
              "      <th>n</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>americans</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>supporting</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>committed</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>revolution</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>citizens</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>generation</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>president</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>forebears</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>powerful</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>themselves</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02d063f5-a602-4b22-9862-34987c9ea3d6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-02d063f5-a602-4b22-9862-34987c9ea3d6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-02d063f5-a602-4b22-9862-34987c9ea3d6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**G. Reflect on the results.**"
      ],
      "metadata": {
        "id": "Ehx6sNfu5cJ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   In the Gutenber corpus we found out that will and might were the most and least frequently used words. Will was used 3807 in bible.text while might was 2 times in the same text.\n",
        "*   In the same corpus 'might' was the least used modal and had the maximum count of 475 times in bible-kjv.txt, whereas had a minimum count of 2 in blake-poems.txt\n",
        "*   The word 'supporting' had the highest number of sysnonyms in the Kennedy text with a count of 52.\n",
        "*   In terms of hyponumns 'america' had the largest count with 75 occurences in the same text. "
      ],
      "metadata": {
        "id": "I9iIgKSS5euN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**H.  Run all the cells, ensure all are executed and create the output. It’s your choice whether to execute locally or on Google Colab.**"
      ],
      "metadata": {
        "id": "ayyfqErl77yZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please hit Ctrl + F9 to run all cells "
      ],
      "metadata": {
        "id": "2Jt8vO3g8Pct"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "*   Hagmann, T. (n.d.). HW 8: Language processing. HW8_tim_hagmann. Retrieved November 19, 2022, from https://timhagmann.com/html/e63/hw8-hagmann-tim.html \n",
        "*   Accessing Text Corpora and Lexical Resources. 2. accessing text corpora and lexical resources. (n.d.). Retrieved November 19, 2022, from https://www.nltk.org/book/ch02.html \n",
        "*   Durai, K. (2022, May 31). Basics of Natural Language Processing for beginners. Medium. Retrieved November 19, 2022, from https://medium.com/geekculture/basics-of-natural-language-processing-for-beginners-d86351df9d09 \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UVTeD8ZAvy-1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QZDILFkvv1GL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}